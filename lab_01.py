# -*- coding: utf-8 -*-
"""lab-01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cCpB4AcM87lVlB8pqsXFvXTktP-OLxUs

# Machine Learning - CS4622 - Lab 01
"""

from google.colab import drive
import pandas as pd
import numpy as np

MOUNT_PATH='/content/drive'
drive.mount(MOUNT_PATH)
WORKING_DIR=f"{MOUNT_PATH}/MyDrive/ML/Lab 01"
train = pd.read_csv(f"{WORKING_DIR}/train.csv")
valid = pd.read_csv(f"{WORKING_DIR}/valid.csv")
test = pd.read_csv(f"{WORKING_DIR}/test.csv")

labels = [f"label_{i+1}" for i in range(4)]
features = [f'feature_{i+1}' for i in range(256)]
label_1 = labels[0]
label_2 = labels[1]
label_3 = labels[2]
label_4 = labels[3]

from sklearn.preprocessing import StandardScaler

X_train = {}
y_train = {}
X_valid = {}
y_valid = {}
X_test = {}
for label in labels:
    train_df = train[train[label_2].notna()] if label == label_2 else train
    valid_df = valid[valid[label_2].notna()] if label == label_2 else valid
    test_df = test
    scaler = StandardScaler()

    # Apply feature scaling to training data
    X_train[label] = pd.DataFrame(scaler.fit_transform(train_df.drop(labels, axis=1)), columns=features)
    y_train[label] = train_df[label]

    # Apply feature scaling to validation data
    X_valid[label] = pd.DataFrame(scaler.transform(valid_df.drop(labels, axis=1)), columns=features)
    y_valid[label] = valid_df[label]

    # Apply feature scaling to test data
    X_test[label] = pd.DataFrame(scaler.transform(test_df.drop(labels, axis=1)), columns=features)

#NaN values have been removed from the dataset of label 2
y_train[label_2]

"""## Label 1

###Initialize SVM model
"""

from sklearn import svm
from sklearn import metrics
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA

model_1_1 = svm.SVC(kernel="linear")
model_1_1.fit(X_train[label_1], y_train[label_1])

"""### Evaluation metrics and confusion matrix:"""

y_pred = model_1_1.predict(X_valid[label_1])
print(metrics.confusion_matrix(y_valid[label_1],y_pred=y_pred))
print("----Before feature engineering----")
print("Accuracy: ", metrics.accuracy_score(y_valid[label_1], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_1],y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_1],y_pred, average="weighted"))

"""### Feature selection using SelectKBest:"""

selector = SelectKBest(f_classif, k=100)
X_new = selector.fit_transform(X_train[label_1], y_train[label_1])
print("Shape :", X_new.shape)

"""### SVM model with selected 100 features"""

model_1_2 = svm.SVC(kernel="linear")
model_1_2.fit(X_new, y_train[label_1])

y_pred = model_1_2.predict(selector.transform(X_valid[label_1]))
print("---Confusion Matrix after SelectKBest---")
print(metrics.confusion_matrix(y_valid[label_1],y_pred=y_pred))
print("Accuracy: ",metrics.accuracy_score(y_valid[label_1],y_pred))
print("Precision: ",metrics.precision_score(y_valid[label_1],y_pred, average="weighted"))
print("Recall: ",metrics.recall_score(y_valid[label_1],y_pred, average="weighted"))

"""### SVM model with PCA transformed features"""

pca = PCA(n_components=0.95,svd_solver='full')
pca.fit(X_train[label_1])
X_train_df = pd.DataFrame(pca.transform(X_train[label_1]))
X_valid_df = pd.DataFrame(pca.transform(X_valid[label_1]))
print("Shape :", X_train_df.shape)

model_1_3 = svm.SVC(kernel="linear")
model_1_3.fit(X_train_df, y_train[label_1])
y_pred = model_1_3.predict(X_valid_df)
print("---Confusion Matrix after PCA---")
print(metrics.confusion_matrix(y_valid[label_1],y_pred=y_pred))
print("Accuracy: ", metrics.accuracy_score(y_valid[label_1], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_1], y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_1], y_pred, average="weighted"))

corr_matrix = X_train[label_1].corr()
# corr_thresh = 0.5
# filtered_corr_matrix = corr_matrix[(corr_matrix > corr_thresh) | (corr_matrix < -corr_thresh)]
plt.figure(figsize=(7, 6))
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Correlation Matrix for label_1')
plt.show()

corr_matrix = X_train_df.corr()
# corr_thresh = 0.5
# filtered_corr_matrix = corr_matrix[(corr_matrix > corr_thresh) | (corr_matrix < -corr_thresh)]
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Correlation Matrix for label_1 after feature engineering')
plt.show()

"""### Testing"""

X_test_df = pd.DataFrame(pca.transform(X_test[label_1]))
y_test_pred = model_1_3.predict(X_test_df)
y_test_before = model_1_1.predict(X_test[label_1])

y_test_pred_df = pd.DataFrame({'Predicted_Label': y_test_pred})
y_test_before_df = pd.DataFrame({'Before_Label': y_test_before})

result_df = pd.concat([y_test_before_df, y_test_pred_df, X_test_df], axis=1)

result_df.to_csv(f"{WORKING_DIR}/result1.csv", index=False)

"""## Label 3"""

train[label_3].info()

import matplotlib.pyplot as plt
import seaborn as sns

value_counts = train[label_3].value_counts()
plt.bar(value_counts.index, value_counts.values)
plt.xlabel(label_3)
plt.ylabel('Frequency')
plt.title('Frequency of '+ label_3)
plt.xticks(value_counts.index)
plt.show()

from sklearn import svm
from sklearn import metrics
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA
model_3_1 = svm.SVC(kernel="linear")
model_3_1.fit(X_train[label_3], y_train[label_3])

y_pred = model_3_1.predict(X_valid[label_3])
print(metrics.confusion_matrix(y_valid[label_3],y_pred=y_pred))
print("----Before feature engineering----")
print("Accuracy: ", metrics.accuracy_score(y_valid[label_3], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_3],y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_3],y_pred, average="weighted"))

"""### Feature selection using SelectKBest:"""

selector = SelectKBest(f_classif, k=15)
X_new = selector.fit_transform(X_train[label_3], y_train[label_3])
print("Shape :", X_new.shape)

model_3_2 = svm.SVC(kernel="linear")
model_3_2.fit(X_new, y_train[label_3])

y_pred = model_3_2.predict(selector.transform(X_valid[label_3]))
print("---Confusion Matrix after SelectKBest---")
print(metrics.confusion_matrix(y_valid[label_3],y_pred=y_pred))
print("Accuracy: ",metrics.accuracy_score(y_valid[label_3],y_pred))
print("Precision: ",metrics.precision_score(y_valid[label_3],y_pred, average="weighted"))
print("Recall: ",metrics.recall_score(y_valid[label_3],y_pred, average="weighted"))

"""### PCA"""

pca = PCA(n_components=0.95,svd_solver='full')
pca.fit(X_train[label_3])
X_train_df = pd.DataFrame(pca.transform(X_train[label_3]))
X_valid_df = pd.DataFrame(pca.transform(X_valid[label_3]))
print("Shape :", X_train_df.shape)

model_3_3 = svm.SVC(kernel="linear")
model_3_3.fit(X_train_df, y_train[label_3])
y_pred = model_3_3.predict(X_valid_df)
print("---Confusion Matrix after PCA---")
print(metrics.confusion_matrix(y_valid[label_3],y_pred=y_pred))
print("Accuracy: ", metrics.accuracy_score(y_valid[label_3], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_3], y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_3], y_pred, average="weighted"))

"""### Testing"""

X_test_df = pd.DataFrame(selector.transform(X_valid[label_3]))
y_test_pred_3 = model_3_2.predict(selector.transform(X_test[label_3]))
y_test_before_3 = model_3_1.predict(X_test[label_3])

y_test_pred_df_3 = pd.DataFrame({'Predicted_Label': y_test_pred_3})
y_test_before_df_3 = pd.DataFrame({'Before_Label': y_test_before_3})

result_df = pd.concat([y_test_before_df_3, y_test_pred_df_3, X_test_df], axis=1)

result_df.to_csv(f"{WORKING_DIR}/result3.csv", index=False)

"""## Label 4"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

# Create a histogram
plt.hist(y_train[label_4], bins=20, edgecolor='k')
plt.xlabel(label_4)
plt.ylabel('Frequency')
plt.title(f'Distribution of {label_4}')
plt.show()

frequency_counts = y_train[label_4].value_counts()
train[label_4].value_counts()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import hamming_loss, jaccard_score

model_4_1 = KNeighborsClassifier(n_neighbors=5)
model_4_1.fit(X_train[label_4], y_train[label_4])
y_pred = model_4_1.predict(X_valid[label_4])
y_pred_before = model_4_1.predict(X_test[label_4])

print(metrics.confusion_matrix(y_valid[label_4],y_pred=y_pred))
print("Accuracy: ", metrics.accuracy_score(y_valid[label_4], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_4],y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_4],y_pred, average="weighted"))

from imblearn.over_sampling import RandomOverSampler

resampler = RandomOverSampler(sampling_strategy='auto')
x_train_resampled, y_train_resampled = resampler.fit_resample(X_train[label_4], y_train[label_4])

plt.hist(y_train_resampled, bins=20, edgecolor='k')
plt.xlabel(label_4)
plt.ylabel('Frequency')
plt.title(f'Distribution of {label_4}')
plt.show()

from sklearn.decomposition import PCA

pca = PCA(n_components=0.95,svd_solver='full')
pca.fit(x_train_resampled)
X_train_df = pd.DataFrame(pca.transform(x_train_resampled))
X_valid_df = pd.DataFrame(pca.transform(X_valid[label_4]))
X_test_df = pd.DataFrame(pca.transform(X_test[label_4]))
print("Shape :", X_train_df.shape)

model_4_2 = KNeighborsClassifier(n_neighbors=5)
model_4_2.fit(X_train_df, y_train_resampled)
y_pred = model_4_2.predict(X_valid_df)
y_pred_after = model_4_2.predict(X_test_df)

print(metrics.confusion_matrix(y_valid[label_4],y_pred=y_pred))
print("Accuracy: ", metrics.accuracy_score(y_valid[label_4], y_pred))
print("Precision: ", metrics.precision_score(y_valid[label_4],y_pred, average="weighted"))
print("Recall: ", metrics.recall_score(y_valid[label_4],y_pred, average="weighted"))

y_pred_df = pd.DataFrame({'Predicted_Label': y_pred_after})
y_before_df = pd.DataFrame({'Before_Label': y_pred_before})

result_df = pd.concat([y_before_df, y_pred_df, X_test_df], axis=1)

result_df.to_csv(f"{WORKING_DIR}/result4.csv", index=False)

"""## Label 2"""

import seaborn as sns
import matplotlib.pyplot as plt

train[label_2].info()

nan_mask = train[label_2].isna()

sns.set(style="whitegrid")

sns.countplot(x=nan_mask, palette="Set2")

plt.xlabel("NaN Values")
plt.ylabel("Count")
plt.title("Presence of NaN Values in Label 2")

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.hist(y_train[label_2], bins=20, edgecolor='k')
plt.xlabel(label_2)
plt.ylabel('Frequency')
plt.title(f'Distribution of {label_2}')
plt.show()

train[label_2].value_counts()

import xgboost as xg
from sklearn.metrics import mean_squared_error as MSE
from sklearn.impute import SimpleImputer

model_2_1 = xg.XGBRegressor()

model_2_1.fit(X_train[label_2], y_train[label_2])

pred_y_before = model_2_1.predict(X_valid[label_2])
pred_y_before_test = model_2_1.predict(X_test[label_2])

# RMSE Computation
print("RMSE : % f" %np.sqrt(MSE(y_valid[label_2], pred_y_before)))

from sklearn.decomposition import PCA

pca = PCA(n_components=0.95,svd_solver='full')
pca.fit(X_train[label_2])
X_train_df = pd.DataFrame(pca.transform(X_train[label_2]))
X_valid_df = pd.DataFrame(pca.transform(X_valid[label_2]))
X_test_df = pd.DataFrame(pca.transform(X_test[label_2]))
print("Shape :", X_train_df.shape)

model_2_2 = xg.XGBRegressor()
model_2_2.fit(X_train_df, y_train[label_2])
pred_y_after = model_2_2.predict(X_valid_df)
pred_y_after_test = model_2_2.predict(X_test_df)

# RMSE Computation
print("RMSE after PCA: % f" %np.sqrt(MSE(y_valid[label_2], pred_y_after)))

corr_matrix = X_train_df.corr()
corr_thresh = 0.1
filtered_corr_matrix = corr_matrix[(corr_matrix > corr_thresh) | (corr_matrix < -corr_thresh)]
plt.figure(figsize=(8, 6))
sns.heatmap(filtered_corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix for label_2')
plt.show()

corr_matrix

"""### Testing"""

y_test_pred_df = pd.DataFrame({'Predicted_Label': pred_y_after_test})
y_test_before_df = pd.DataFrame({'Before_Label': pred_y_before_test})

result_df = pd.concat([y_test_before_df, y_test_pred_df, X_test_df], axis=1)

result_df.to_csv(f"{WORKING_DIR}/result2.csv", index=False)